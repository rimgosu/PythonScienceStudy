회귀 : 정답이 연속적인 수치값, y햇이 예측한 값을 그대로 사용 
분류 : 정답이 딱 떨어지는 정해져 있는 값

선형분류 : y햇이라는 선형함수(결정경계)를 기준으로 결정경계의 위쪽에 있느냐,
               아래쪽에 있느냐로 영역을 예측하는 것
               가중치들의 합 > 0  ==> 1
          가중치들의 합 < 0 ==> 0 

Logistic Regression
- 결정경계가 S자형 곡선으로 그려짐
- Sigmoid(S자형 곡선)라는 선형함수를 사용
- sigmoid는 입력값을 0 ~ 1범위로 변환, 확률값으로 사용
   ex) 개와 고양이를 분류하는 모델 : 개(70%), 고양이(80%)  ==> 예측하는 확률값을 명시
   sigmoid 함수(곡선)를 잘 그렸는지 확인하는 기준 ==> 교차엔트로피 오차함수
   - 오차들을 더해서 오차가 크면 ==> 안 좋은 함수
   - 오차들을 더해서 오차가 작으면 ==> 좋은 함수 

선형회귀 --> MSE, R2score(직선)
로지스틱회귀 --> 교차엔트로피 오차함수(곡선)
SVM --> 마진 

SVM
- 결정경계(초평면)와 가장 인접한 데이터 : 서포트 벡터
- 결정경계(초평면)와 서포트 벡터간의 거리 : 마진 
- 마진이 가장 큰 결정경계가 가장 좋은 결정경계 
- 결정경계(초평면)가 데이터(N)가 가지고 있는 차원(N-1)으로 구성함